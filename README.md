# AlphaMWE
AlphaMWE: Construction of Multilingual Parallel Corpora with MWE Annotations

In this work, we present the construction of multilingual parallel corpora with annotation of multiword expressions (MWEs). 
The MWEs include the verbal MWEs (vMWEs) defined by the PARSEME shared task that have a verb as the head of the studied terms. 
The annotated vMWEs are also bilingual and multilingual aligned manually. The languages covered include English, Chinese, Polish, and German. 
Our original English corpus is taken from the PARSEME shared task in 2018. 
We performed machine translation of this source corpus followed by human post editing and annotation of target MWEs. 
Strict quality control was applied for error limitation, i.e., each MT output sentence received first person post editing and annotation plus second person quality checking. 
One of our findings during corpora preparation is that accurate translation of MWEs presents challenges to MT systems. 
To facilitate further MT research, we present a categorisation of the error types encountered by MT systems in performing MWE related translations. 
To acquire a broader view of MT issues, we selected four popular and state-of-the-art MT models for comparisons namely Microsoft Bing Translator, GoogleMT, Baidu Fanyi and DeepL MT. 
Because of the noise removal, translation post editing and MWE annotation by human professionals, 
we believe AlphaMWE is an asset for cross-lingual and multilingual research, such as MT and information extraction. Our multilingual corpora are available.


Citation:

Lifeng han, Gareth Jones, and Alan Smeaton. 2020. AlphaMWE: Construction of Multilingual Parallel Corpora with MWE Annotations. Forthcoming in Joint Workshop on Multiword Expressions and Electronic Lexicons (MWE-LEX) @COLING-2020. Barcelona, Spain.
